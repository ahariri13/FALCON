{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fixedNode.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL8KokLB17dp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6f62df69-db03-4674-911f-4b78234470d5"
      },
      "source": [
        "!pip install -q torch==1.4.0 torchvision==0.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 753.4MB 21kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0MB 55.6MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF4pkOUe19Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
        "!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
        "!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
        "!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
        "!pip install torch-geometric\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1nhuVyQ2f9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install \"neuralnet-pytorch[geom] @ git+git://github.com/justanhduc/neuralnet-pytorch.git@master\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyIWh23w2m0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install neuralnet-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PmWlRgE2pDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install git+git://github.com/justanhduc/neuralnet-pytorch.git@fancy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymojjBBDzou8",
        "colab_type": "text"
      },
      "source": [
        "**Go to directory where the model and data are stored**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWDNTG5T4NBy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b68f8dce-eb9c-44fd-c678-72d6da6fafca"
      },
      "source": [
        "cd drive/My\\ Drive/Gitlink/Version1_Fixed\\ Nodes"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Gitlink/Version1_Fixed Nodes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9u2_PMm0_Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import all potential models, files and functions that could be useful\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import time\n",
        "import torch_geometric\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch_geometric.data import Data\n",
        "from model import GCN_Message\n",
        "from optimizer2 import loss_function\n",
        "#from utils import load_data, mask_test_edges, preprocess_graph, get_roc_score\n",
        "import torch.nn.functional as F\n",
        "import time \n",
        "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
        "from itertools import cycle, islice\n",
        "import iterableJet\n",
        "from iterableJet import IterableMuons\n",
        "import class_jet\n",
        "from class_jet import FCMuonsGPU\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAb5wkOLs5oU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model', type=str, default='gcn_vae', help=\"models used\")\n",
        "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
        "parser.add_argument('--epochs', type=int, default=50, help='Number of epochs to train.')\n",
        "parser.add_argument('--batch_size', type=int, default=100, help='Initial learning rate.') #100\n",
        "parser.add_argument('--lr', type=float, default=0.0001, help='Initial learning rate.') #0.001\n",
        "parser.add_argument('--dropout', type=float, default=0.2, help='Dropout rate (1 - keep probability).')\n",
        "args = parser.parse_args([])\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ojycy2f1zNl",
        "colab_type": "text"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiacyJVa4WsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples=torch.load('../../Unet/ECAL_f01_june.pt')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuOpvGdNtT-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Log-Scaling of the last column containing energies to make it within the same range of the positions (columns 0 and 1)\n",
        "for sample in samples:\n",
        "    sample['x'][:,2]=torch.log(sample['x'][:,2])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCog9VR12BWv",
        "colab_type": "text"
      },
      "source": [
        "**Define model and optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iey5DBeMtSIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "b6b66434-9812-4cbc-86f4-d74a92c93d3d"
      },
      "source": [
        "## Use Iterable Dataset to better load the batches\n",
        "from torch_geometric.data import DataLoader\n",
        "jet=IterableMuons(samples)\n",
        "loader = DataLoader(jet, batch_size=args.batch_size)\n",
        "\n",
        "## Initialize the model \n",
        "model = GCN_Message(in_channels=3, out_channels1=64, out_channels2=128,out_channels3=512, deco2=512,deco3=128,deco4=64,num_layers=3, dropout=0.2,\n",
        "                    batch_size=args.batch_size)\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "## If training for the first time, otherwise uncomment cell below and use it to load weights\n",
        "model.train()\n",
        "model.to(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GCN_Message(\n",
              "  (dec1): Linear(in_features=64, out_features=512, bias=True)\n",
              "  (dec2): SAGEConv(512, 128)\n",
              "  (dec3): SAGEConv(128, 64)\n",
              "  (dec4): SAGEConv(64, 3)\n",
              "  (ggn): SAGEConv(3, 64)\n",
              "  (ggn2): SAGEConv(64, 128)\n",
              "  (ggn3): SAGEConv(128, 512)\n",
              "  (tr2): Linear(in_features=512, out_features=64, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64TPvdMbeDsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "d445e2a0-b1e5-48ef-dd55-2c3ff61d0682"
      },
      "source": [
        "\"\"\"\n",
        "checkpoint = torch.load('best_weights.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "for state in optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "model.train()\n",
        "model.to(device)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GCN_Message(\n",
              "  (lin1): Linear(in_features=3, out_features=150, bias=True)\n",
              "  (lin2): Linear(in_features=150, out_features=150, bias=True)\n",
              "  (gc1): GCNConv_Message(150, 100)\n",
              "  (gc2): GCNConv_Message(150, 100)\n",
              "  (dec1): Linear(in_features=64, out_features=512, bias=True)\n",
              "  (dec2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (dec3): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (dec4): Linear(in_features=64, out_features=3, bias=True)\n",
              "  (lin3): Linear(in_features=1, out_features=20, bias=True)\n",
              "  (lin32): Linear(in_features=20, out_features=4, bias=True)\n",
              "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (ggn): GatedGraphConv(150, num_layers=3)\n",
              "  (tr1): Linear(in_features=150, out_features=100, bias=True)\n",
              "  (tr2): Linear(in_features=100, out_features=64, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxCqWvsa47Om",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "eb34f7b1-385f-4d09-b137-6cbb33a9c90b"
      },
      "source": [
        "for epoch in range(25):\n",
        "    #model.train()\n",
        "    count=0\n",
        "    epLoss=0\n",
        "    t = time.time()\n",
        "    for el in islice(loader,0,600):\n",
        "        gra=el.x.clone()  ##features \n",
        "\n",
        "        adj=el.edge_index ## edge matrix \n",
        "\n",
        "        count+=1\n",
        "        hidden_emb = None\n",
        "        orig=torch_geometric.data.Batch.to_data_list(el)\n",
        "\n",
        "        gra=gra.to(device)\n",
        "        adj=adj.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        r1,r2, mu, logvar = model(gra,adj) ## X , A \n",
        "\n",
        "        loss = loss_function(r1,r2,labels=gra, mu=mu, logvar=logvar, n_nodes=32) #+loss2(logsoftmax(torch.transpose(r2,1,2)),temp.long())     \n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        \n",
        "        cur_loss = loss.item()\n",
        "        optimizer.step()\n",
        "        epLoss+=cur_loss\n",
        "\n",
        "        hidden_emb = mu.data.cpu().numpy() \n",
        "        \n",
        "        if count%300==0:\n",
        "            print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(epLoss/count),\n",
        "                  \"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "            t = time.time()\n",
        "        if epoch %2==0:\n",
        "            #%%\n",
        "            torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              }, './best_weights.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 train_loss= 3790.13913 time= 38.23780\n",
            "Epoch: 0001 train_loss= 3529.55882 time= 37.28699\n",
            "Epoch: 0002 train_loss= 2905.64882 time= 26.19760\n",
            "Epoch: 0002 train_loss= 2729.80042 time= 26.26918\n",
            "Epoch: 0003 train_loss= 2269.81774 time= 37.39830\n",
            "Epoch: 0003 train_loss= 2129.62984 time= 37.43444\n",
            "Epoch: 0004 train_loss= 1766.32057 time= 26.42065\n",
            "Epoch: 0004 train_loss= 1655.66989 time= 26.23539\n",
            "Epoch: 0005 train_loss= 1373.34557 time= 37.48415\n",
            "Epoch: 0005 train_loss= 1288.04225 time= 37.88875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL3mhd-vlAjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "224215e5-f084-46ae-80ae-ab3ee204e6a3"
      },
      "source": [
        "\n",
        "from torch_geometric.data import DataLoader\n",
        "#jetTest=IterableMuons(testing)\n",
        "#Testloader = DataLoader(testing, batch_size=200)\n",
        "#%%\n",
        "\n",
        "model.eval()\n",
        "#count2=0\n",
        "epLoss2=0\n",
        "\n",
        "\n",
        "tests=torch.load('../f11.pt')\n",
        "cols=None\n",
        "#model.train()\n",
        "count2=0\n",
        "epLoss2=0\n",
        "t = time.time()\n",
        "i12,i22=0,200\n",
        "#data2=get_slice(i12,i22)\n",
        "#jet=IterableMuons(samples)\n",
        "for k2 in range(2):\n",
        "    count2+=1\n",
        "    loader2 = DataLoader(tests, batch_size=200)\n",
        "    for el2 in islice(loader,0,1):#for k,(gra, feats) in enumerate(loader): \n",
        "        gra2=el2.x.clone()  ##features \n",
        "\n",
        "        adj2=el2.edge_index ## edge matrix \n",
        "\n",
        "        \n",
        "        hidden_emb2 = None\n",
        "        orig2=torch_geometric.data.Batch.to_data_list(el2)\n",
        "      \n",
        "        #gra[:,:2]/=10\n",
        "\n",
        "        #gra[:,2]*=16\n",
        "        gra2[:,2]*=16\n",
        "\n",
        "        #gra_baseline=normBatch(gra_baseline).float()\n",
        "\n",
        "        gra2=gra2.to(device)\n",
        "        adj2=adj2.to(device)\n",
        "        #gra_baseline=gra_baseline.to(device)\n",
        "        #optimizer.zero_grad()\n",
        "                \n",
        "        #gra_baseline=gra_baseline.to(device)\n",
        "        r12,r22, mu2, logvar2 = model(gra2,adj2) ## X , A \n",
        "\n",
        "        #temp=gra[:,:,3].clone()\n",
        "        loss2 = loss_function(r12,r22,labels=gra2, mu=mu2, logvar=logvar2, n_nodes=32) #+ loss3(torch.abs(detector2),gra2[:,3])      #gra_baseline[:,:,-1:].squeeze_(2).long())#+BCLoss(r2,gra) \n",
        "\n",
        "\n",
        "        cur_loss2 = loss2.item()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        hidden_emb2 = mu2.data.cpu().numpy()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VikJXUx5qtPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "orig2=torch_geometric.data.Batch.to_data_list(el2)\n",
        "com2=r12.detach().cpu().clone()\n",
        "com3=r22.detach().cpu().clone()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sDJfH3xqvEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "com4=torch.cat((com2,com3.unsqueeze_(1)),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZPfDAg3sldz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "1d8556d6-bc79-467c-b91b-9f4e24bdf7b0"
      },
      "source": [
        "orig2[0].clone()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(edge_index=[2, 324], x=[81, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU7bkDBjspsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec2[0].clone().shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr0s3en3QYYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec2=[]\n",
        "i3,i4=0,0\n",
        "for jet2 in orig2:\n",
        "  size2=jet2['x'].shape[0]\n",
        "  i4+=size2\n",
        "  rec2.append(com4[i3:i4])\n",
        "  i3+=size2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkZzXTcwq_Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import LogNorm\n",
        "#xmin, xmax = min(lis4[:,0]), max(lis4[:,0])\n",
        "#ymin, ymax = min(lis4[:,1]), max(lis4[:,1])\n",
        "for m in range(20):\n",
        "    lis4=rec2[m].clone()\n",
        "    lis4=lis4.detach().numpy()\n",
        "    xmin,xmax=0,500\n",
        "    ymin,ymax=0,500\n",
        "    binsxy = [int((xmax - xmin) / 50), int((ymax - ymin) / 50)]\n",
        "    weights=np.exp(lis4[:,2]/16)\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sc = plt.scatter(lis4[:,0],lis4[:,1],c=weights,cmap='viridis',norm=LogNorm(), alpha=0.9)\n",
        "    plt.colorbar(sc)\n",
        "    check=np.arange(0,500,25)\n",
        "    plt.xticks(check)\n",
        "    plt.yticks(check)\n",
        "    plt.grid()\n",
        "    #plt.show()\n",
        "    plt.savefig('./figs_rec/recScale'+str(m)+'.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSQ1VOcXq2it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec2=[]\n",
        "i3,i4=0,0\n",
        "for jet2 in orig2:\n",
        "  size2=jet2['x'].shape[0]\n",
        "  i4+=size2\n",
        "  rec2.append(com4[i3:i4])\n",
        "  i3+=size2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BmQEr9rtDxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import LogNorm\n",
        "#xmin, xmax = min(lis4[:,0]), max(lis4[:,0])\n",
        "#ymin, ymax = min(lis4[:,1]), max(lis4[:,1])\n",
        "for m in range(20):\n",
        "    lis4=orig2[m]['x'].clone()\n",
        "    lis4=lis4.detach().numpy()\n",
        "    xmin,xmax=0,500\n",
        "    ymin,ymax=0,500\n",
        "    binsxy = [int((xmax - xmin) / 50), int((ymax - ymin) / 50)]\n",
        "    weights=np.exp(lis4[:,2]/16)\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sc = plt.scatter(lis4[:,0],lis4[:,1],c=weights,cmap='viridis',norm=LogNorm(), alpha=0.9)\n",
        "    plt.colorbar(sc)\n",
        "    check=np.arange(0,500,25)\n",
        "    plt.xticks(check)\n",
        "    plt.yticks(check)\n",
        "    plt.grid()\n",
        "    #plt.show()\n",
        "    plt.savefig('./figs_real/realScale'+str(m)+'.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7FjCycNsf3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch_geometric.transforms\n",
        "from torch_geometric.transforms import RadiusGraph\n",
        "from torch_geometric.transforms import knn_graph\n",
        "import torch_geometric.data\n",
        "import torch \n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial import distance_matrix\n",
        "import torch\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch_geometric.nn import knn_graph\n",
        "\n",
        "parquet = pq.ParquetFile('../Boosted_Jets_Sample-4.snappy.parquet')\n",
        "cols = None\n",
        "#%%\n",
        "\n",
        "def jets(number1,number2):\n",
        "    allCords=[]\n",
        "    graphs=[]\n",
        "    allFeats2=[]\n",
        "    grIndex=[]\n",
        "    for i in range(number1,number2):\n",
        "        data = parquet.read_row_group(i, columns=cols).to_pydict()\n",
        "        \n",
        "        data['X_jets'] = np.float32(data['X_jets']) [0]\n",
        "        \n",
        "        ecal=data['X_jets'][1]\n",
        "\n",
        "        ecal[ecal<=1e-3]=0\n",
        "        \n",
        "        xhit2,yhit2=np.nonzero(ecal)\n",
        "        \n",
        "\n",
        "        eneEcal=ecal[xhit2,yhit2]\n",
        "\n",
        "        \n",
        "        feats=np.transpose(np.vstack((xhit2,yhit2,eneEcal)))\n",
        "        \n",
        "        \n",
        "        cords=feats[:,[0,1]]\n",
        "        \n",
        "        allFeats=torch.from_numpy(feats).float()\n",
        "        \n",
        "        cords2=torch.from_numpy(cords)\n",
        "        \n",
        "       \n",
        "        edge_index = knn_graph(cords2, k=4, batch=None, loop=True)\n",
        "        data=Data(x=allFeats,edge_index=edge_index)\n",
        "        \n",
        "        graphs.append(data)\n",
        "\n",
        "\n",
        "    return graphs \n",
        "\n",
        "#%%\n",
        "testing=jets(0,1000)\n",
        "\n",
        "#%%\n",
        "for sample2 in testing:\n",
        "    sample2['x'][:,2]=torch.log(sample2['x'][:,2])\n",
        "#%%\n",
        "testingFile=torch.load('ECAL_file1_30k.pt')\n",
        "\n",
        "testing=testingFile[:5000]\n",
        "\n",
        "torch.save(testing,'ECAL_test_real.pt')\n",
        "#%%\n",
        "lis3=testing[5]['x'].clone()\n",
        "#lis3[:,2]=np.exp(lis3[:,2])\n",
        "lis3=lis3.numpy()\n",
        "#lis3[:,2]*=4\n",
        "#%%\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "for n in range(100):\n",
        "    lis3=testing[n]['x'].clone()\n",
        "    #lis3[:,2]=np.exp(lis3[:,2])\n",
        "    lis3=lis3.numpy()\n",
        "    xmin, xmax = min(lis3[:,0]), max(lis3[:,0])\n",
        "    ymin, ymax = min(lis3[:,1]), max(lis3[:,1])\n",
        "    \n",
        "    binsxy = [int((xmax - xmin) / 50), int((ymax - ymin) / 50)]\n",
        "    \n",
        "    weights=np.exp(lis3[:,2])\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sc = plt.scatter(lis3[:,0],lis3[:,1],c=weights,  cmap='viridis', norm=LogNorm(),alpha=0.9)\n",
        "    plt.colorbar(sc)\n",
        "    check=np.arange(0,140,10)\n",
        "    plt.xticks(check)\n",
        "    plt.yticks(check)\n",
        "    plt.grid()\n",
        "    #plt.show()\n",
        "    plt.savefig('./figs_real_scale/realScale'+str(n)+'.png')\n",
        "\n",
        "#%%\n",
        "    n=0\n",
        "    lis3=testing[n]['x'].clone()\n",
        "    #lis3[:,2]=np.exp(lis3[:,2])\n",
        "    lis3=lis3.numpy()\n",
        "    xmin, xmax = min(lis3[:,0]), max(lis3[:,0])\n",
        "    ymin, ymax = min(lis3[:,1]), max(lis3[:,1])\n",
        "    \n",
        "    binsxy = [int((xmax - xmin) / 50), int((ymax - ymin) / 50)]\n",
        "    \n",
        "    weights=np.exp(lis3[:,2])\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sc = plt.scatter(lis3[:,0],lis3[:,1],c=weights,  cmap='viridis',norm=LogNorm(), alpha=0.9)\n",
        "    plt.colorbar(sc)\n",
        "    check=np.arange(0,140,10)\n",
        "    plt.xticks(check)\n",
        "    plt.yticks(check)\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "#%%\n",
        "from torch_geometric.data import DataLoader\n",
        "#jetTest=IterableMuons(testing)\n",
        "Testloader = DataLoader(testing, batch_size=100)\n",
        "#%%\n",
        "model.eval()\n",
        "count2=0\n",
        "epLoss2=0\n",
        "\n",
        "posMom=[]\n",
        "#detector=[]\n",
        "with torch.no_grad():\n",
        "  for el2 in islice(Testloader,1):#for k,(gra, feats) in enumerate(loader): \n",
        "\n",
        "    gra2=el2.x  ##features \n",
        "    adj2=el2.edge_index ## edge matrix \n",
        "    #gra_baseline2=el2.x.clone().reshape(args.batch_size,2000,4)\n",
        "    #gra2[:,2]*=5\n",
        "    count2+=1\n",
        "    hidden_emb2 = None\n",
        "    \n",
        "    #gra2[:,2]=torch.exp(-gra2[:,2])\n",
        "    #gra2[:,2]*=16\n",
        "    #gra2[:,2]=torch.log(gra2[:,2]\n",
        "    \n",
        "    #gra2[:,2]=torch.log(gra2[:,2])\n",
        "\n",
        "    #gra_baseline2=normBatch(gra_baseline2).float()\n",
        "\n",
        "    gra2=gra2.to(device)\n",
        "    adj2=adj2.to(device)\n",
        "    #gra_baseline2=gra_baseline2.to(device)\n",
        "    r12,r22, mu2, logvar2 = model(gra2,adj2) ## X , A \n",
        "    loss2 = loss_function(r12,r22,labels=gra2, mu=mu2, logvar=logvar2, n_nodes=32) #+loss2(logsoftmax(torch.transpose(r2,1,2)),temp.long())      #gra_baseline[:,:,-1:].squeeze_(2).long())#+BCLoss(r2,gra) \n",
        "    cur_loss2 = loss2.item()\n",
        "    posMom.append(torch.cat((r12,r22.unsqueeze_(1)),axis=1))\n",
        "    #detector.append(r22)\n",
        "#%%\n",
        "orig2=torch_geometric.data.Batch.to_data_list(el2)\n",
        "com2=r12.detach().cpu().clone()\n",
        "com3=r22.detach().cpu().clone()\n",
        "\n",
        "#%%\n",
        "com4=torch.cat((com2,com3.squeeze_(1)),axis=1)\n",
        "#%%\n",
        "rec2=[]\n",
        "i3,i4=0,0\n",
        "for jet2 in orig2:\n",
        "  size2=jet2['x'].shape[0]\n",
        "  i4+=size2\n",
        "  rec2.append(com4[i3:i4])\n",
        "  i3+=size2\n",
        "\n",
        "#%%\n",
        "lis4=rec2[5].clone()\n",
        "lis4=lis4.detach().numpy()\n",
        "#lis4[:,2]=1/np.exp((lis4[:,2]-20)/10)\n",
        "#lis4[:,2]=1/lis4[:,2]\n",
        "\n",
        "#lis4[:,2]/=4\n",
        "#lis4[:,2]/=16\n",
        "#lis4[:,2]=-np.exp(lis4[:,2])\n",
        "#lis4[:,2]*=4\n",
        "#lis4[:,2]=np.abs(lis4[:,2])\n",
        "\n",
        "\"\"\"\n",
        "lis4[:,2]/=4\n",
        "\"\"\"\n",
        "#lis4[:,:2]+=42\n",
        "#%%\n",
        "lis4\n",
        "#%%\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import LogNorm\n",
        "#xmin, xmax = min(lis4[:,0]), max(lis4[:,0])\n",
        "#ymin, ymax = min(lis4[:,1]), max(lis4[:,1])\n",
        "for m in range(100):\n",
        "    lis4=rec2[m].clone()\n",
        "    lis4=lis4.detach().numpy()\n",
        "    xmin,xmax=0,125\n",
        "    ymin,ymax=0,125\n",
        "    binsxy = [int((xmax - xmin) / 50), int((ymax - ymin) / 50)]\n",
        "    weights=np.exp(lis4[:,2])\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sc = plt.scatter(lis4[:,0],lis4[:,1],c=weights,cmap='viridis',norm=LogNorm(), alpha=0.9)\n",
        "    plt.colorbar(sc)\n",
        "    check=np.arange(0,140,10)\n",
        "    plt.xticks(check)\n",
        "    plt.yticks(check)\n",
        "    plt.grid()\n",
        "    #plt.show()\n",
        "    plt.savefig('./figs_rec_scale/recScale'+str(m)+'.png')\n",
        "#%%\n",
        "len(rec2)\n",
        "#%%\n",
        "\"\"\"\n",
        "Testing\n",
        "\"\"\"\n",
        "from torch_geometric.data import DataLoader\n",
        "jetTest=IterableMuons(testing)\n",
        "Testloader = DataLoader(jetTest, batch_size=100)\n",
        "#%%\n",
        "model.eval()\n",
        "count2=0\n",
        "epLoss2=0\n",
        "\n",
        "PredAll=[]\n",
        "posMom=[]\n",
        "#detector=[]\n",
        "with torch.no_grad():\n",
        "  for el2 in islice(Testloader,10):#for k,(gra, feats) in enumerate(loader): \n",
        "\n",
        "    gra2=el2.x  ##features \n",
        "    adj2=el2.edge_index ## edge matrix \n",
        "    #gra_baseline2=el2.x.clone().reshape(args.batch_size,2000,4)\n",
        "    #gra2[:,2]*=5\n",
        "    count2+=1\n",
        "    hidden_emb2 = None\n",
        "    \n",
        "\n",
        "    #gra2[:,2]*=16\n",
        "\n",
        "\n",
        "    #gra_baseline2=normBatch(gra_baseline2).float()\n",
        "\n",
        "    gra2=gra2.to(device)\n",
        "    adj2=adj2.to(device)\n",
        "    #gra_baseline2=gra_baseline2.to(device)\n",
        "    r12,r22, mu2, logvar2 = model(gra2,adj2) ## X , A \n",
        "    loss2 = loss_function(r12,r22,labels=gra2, mu=mu2, logvar=logvar2, n_nodes=32) #+loss2(logsoftmax(torch.transpose(r2,1,2)),temp.long())      #gra_baseline[:,:,-1:].squeeze_(2).long())#+BCLoss(r2,gra) \n",
        "    cur_loss2 = loss2.item()\n",
        "    posMom.append(r12)\n",
        "    orig2=torch_geometric.data.Batch.to_data_list(el2)\n",
        "    com2=r12.detach().cpu().clone()\n",
        "    com3=torch.exp(r22.detach().cpu().clone())\n",
        "    com4=torch.cat((com2,com3.unsqueeze_(1)),axis=1)\n",
        "    rec2=[]\n",
        "    i3,i4=0,0\n",
        "    for jet2 in orig2:\n",
        "        size2=jet2['x'].shape[0]\n",
        "        i4+=size2\n",
        "        rec2.append(com4[i3:i4])\n",
        "        i3+=size2\n",
        "    PredAll+=rec2\n",
        "\n",
        "    #detector.append(r22)\n",
        "#%%\n",
        "PredAll[0]\n",
        "#%%\n",
        "testing[0]['x'].\n",
        "#%%\n",
        "torch.save(testing,'real_120k_None.pt') \n",
        "#%%\n",
        "torch.save(PredAll,'rec_120k_None.pt')    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BSXJYAneWHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing = samples[-330:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbIS-8CfeWbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}