{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqUFgLSb5eFF",
        "colab_type": "text"
      },
      "source": [
        "In this code, we aim to use Edge Pooling and Unpooling in order to reconstruct the events. The main message passing technique so far is SAGE, and the main loss functions are MSE and Chamfer Distance "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha6zO9mFe09Q",
        "colab_type": "text"
      },
      "source": [
        "# Libraries Installation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A52qcrwYecyr",
        "colab_type": "text"
      },
      "source": [
        "Import Pytorch Version 1.4 for compatibility with some libraries to be used like neural-net pytorch that contains EMD and Chamfer Distance Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6bbzlRv225X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q torch==1.4.0 torchvision==0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmFT0LIh3Hb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
        "!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
        "!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
        "!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
        "!pip install torch-geometric\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaN4zqUT3LeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install \"neuralnet-pytorch[geom] @ git+git://github.com/justanhduc/neuralnet-pytorch.git@master\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_znfZzdt3Lwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install neuralnet-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX-_4ReRvAi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install git+git://github.com/justanhduc/neuralnet-pytorch.git@fancy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRmb5L3orBi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br6OzWHT3MLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd drive/My\\ Drive/gae/fast_gae/ECAL/temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK14_N4q3TdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import time\n",
        "import torch_geometric\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
        "from itertools import cycle, islice\n",
        "from torch_geometric.utils import dropout_adj\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QM3HnGv3UB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from optimizer import loss_function\n",
        "import iterableJet\n",
        "from iterableJet import IterableMuons\n",
        "import class_jet\n",
        "from class_jet import FCMuonsGPU\n",
        "from model import GraphPooling\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
        "parser.add_argument('--epochs', type=int, default=50, help='Number of epochs to train.')\n",
        "parser.add_argument('--batch_size', type=int, default=200, help='Initial learning rate.') #100\n",
        "\n",
        "parser.add_argument('--lr', type=float, default=0.0001, help='Initial learning rate.') #0.001\n",
        "parser.add_argument('--dropout', type=float, default=0.4, help='Dropout rate (1 - keep probability).')\n",
        "args = parser.parse_args([])\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_8FK_2k3YDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples=torch.load('../ECAL Data /ECAL_f01_june_60k.pt')#\n",
        "#samples=torch.load('../ECAL Data /ECAL_f01_june_60k.pt')\n",
        "#samples=torch.load('../padded_June/newPad_0.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KxH1Zidrb04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#samples=samples[:30000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjeSoo48AQGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sam in samples:\n",
        "  sam['x'][:,2]=-torch.log(sam['x'][:,2])*15\n",
        "  #sam['x'][:,:2]/=150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3yNn7Hl3mj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = AliPooling(in_channels=3, out_channels1=64, out_channels2=128, out_channels3=256,out_channels4=512,out_channels5=1024,dropout=args.dropout,\n",
        "                    batch_size=args.batch_size)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.001)\n",
        "#optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0rme5CK3qAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sizer(samples):\n",
        "    inds=[]\n",
        "    for k in samples:\n",
        "        inds.append(k['x'].shape[0])\n",
        "    return inds\n",
        "\n",
        "sizes=sizer(samples[:58000])\n",
        "\n",
        "fin=[]\n",
        "countit=0\n",
        "for m in sizes:\n",
        "    fin.append(np.repeat(countit,m))\n",
        "    countit+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IVl3CZTaeZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from torch_geometric.data import DataLoader\n",
        "#jet=IterableMuons(samples)\n",
        "loader = DataLoader(samples[:58000], batch_size=args.batch_size,num_workers=2,pin_memory=True)\n",
        "\n",
        "#%%\n",
        "#model.train()\n",
        "#model= model.to(device)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.001)\n",
        "#optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0005, weight_decay=0.001)\n",
        "#model.train()\n",
        "#model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfhL1WQyXQEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler=StepLR(optimizer, step_size=4, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a3i0jPjac9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "789e7b57-3446-48ee-e43d-645ee5dcbe54"
      },
      "source": [
        "checkpoint = torch.load('edge_mse_august.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "for state in optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AliPooling(\n",
              "  (sage1): SAGEConv(3, 64)\n",
              "  (sage2): SAGEConv(64, 128)\n",
              "  (sage3): SAGEConv(128, 256)\n",
              "  (sage4): SAGEConv(256, 512)\n",
              "  (tr1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "  (tr2): Linear(in_features=1024, out_features=2048, bias=True)\n",
              "  (bano1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dec0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "  (dec1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (dec2): SAGEConv(512, 256)\n",
              "  (dec3): SAGEConv(256, 128)\n",
              "  (dec4): SAGEConv(128, 64)\n",
              "  (dec5): SAGEConv(64, 3)\n",
              "  (edge1): EdgePooling(64)\n",
              "  (edge2): EdgePooling(128)\n",
              "  (edge3): EdgePooling(256)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spqMMBqBrtED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing = samples[-1000:]\n",
        "\n",
        "sizes2=sizer(testing)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHyIPbrUrw-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "fin2=[]\n",
        "count23=0\n",
        "for m2 in sizes2:\n",
        "    fin2.append(np.repeat(count23,m2))\n",
        "    count23+=1\n",
        "\n",
        "from torch_geometric.data import DataLoader\n",
        "Testloader = DataLoader(testing, batch_size=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWfdP9-IIE-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch2=checkpoint['epoch']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOeROG5WIBKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "243c239a-6434-41bf-cebe-021bd75a2524"
      },
      "source": [
        "for epoch in range(epoch2,50):\n",
        "    #model.train()\n",
        "    \n",
        "    count=0\n",
        "    c1,c2=0,args.batch_size\n",
        "    epLoss=0\n",
        "    t = time.time()\n",
        "    for el in islice(loader,0,290):#count2,el in enumerate(loader):\n",
        "        \n",
        "        gra=el.x\n",
        "        adj=el.edge_index\n",
        "\n",
        "\n",
        "\n",
        "        check=torch.LongTensor(np.hstack(np.array(fin[c1:c2])))\n",
        "        count+=1#=count2+1\n",
        "        hidden_emb = None\n",
        "        \n",
        "        gra=gra.to(device)\n",
        "        adj=adj.to(device)\n",
        "        lengs=check.to(device)\n",
        "        optimizer.zero_grad()\n",
        "       \n",
        "\n",
        "        r1 ,mu,sig= model(gra,adj,lengs,gra.shape[0])\n",
        "\n",
        "\n",
        "        loss = loss_function(r1,gra,lengs,mu,sig) #+loss2(logsoftmax(torch.transpose(r2,1,2)),temp.long())      \n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        \n",
        "\n",
        "        cur_loss = loss.item()\n",
        "\n",
        "        \n",
        "        torch.cuda.empty_cache() \n",
        "        \n",
        "        epLoss+=float(cur_loss)\n",
        "\n",
        "        #hidden_emb = mu.data.numpy() \n",
        "\n",
        "\n",
        "        c1+=args.batch_size\n",
        "        c2+=args.batch_size\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        if count%145==0:\n",
        "            print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(epLoss/count),\"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "            t = time.time()\n",
        "\n",
        "            with torch.no_grad():\n",
        "              model.eval()\n",
        "              VaLoss=0\n",
        "              d1,d2=0,100\n",
        "              for el2 in islice(Testloader,10):\n",
        "                gra2=el2.x.cuda()  ##features \n",
        "                adj2=el2.edge_index.cuda() ## edge matrix \n",
        "                lengs2=torch.LongTensor(np.hstack(np.array(fin2[d1:d2]))).cuda()\n",
        "                r12,mu2,sig2= model(gra2,adj2,lengs2,gra2.shape[0]) ## X , A \n",
        "                loss2 = loss_function(r12,gra2,lengs2,mu2,sig2)\n",
        "                cur_loss2 = loss2.item()\n",
        "                VaLoss+=float(cur_loss2)\n",
        "                d1+=100\n",
        "                d2+=100\n",
        "              print(\"Val Loss:\", '%04d' % (VaLoss/10))\n",
        "\n",
        "    if epoch%2==0:\n",
        "      scheduler.step()\n",
        "      #cumLoss=validate(Testloader,5)\n",
        "      torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'epoch':epoch,\n",
        "            'loss': loss,\n",
        "            'epLoss':epLoss\n",
        "            }, './edge_mse_august.pth')\n",
        "\n",
        "           "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0031 train_loss= 2413.71838 time= 1525.71009\n",
            "Val Loss: 1389\n",
            "Epoch: 0031 train_loss= 1887.91755 time= 1581.23402\n",
            "Val Loss: 1384\n",
            "Epoch: 0032 train_loss= 1364.61513 time= 1548.64045\n",
            "Val Loss: 1381\n",
            "Epoch: 0032 train_loss= 1359.91757 time= 1581.25350\n",
            "Val Loss: 1378\n",
            "Epoch: 0033 train_loss= 1359.44634 time= 1554.17089\n",
            "Val Loss: 1376\n",
            "Epoch: 0033 train_loss= 1355.17816 time= 1592.36344\n",
            "Val Loss: 1374\n",
            "Epoch: 0034 train_loss= 1355.62953 time= 1556.70469\n",
            "Val Loss: 1373\n",
            "Epoch: 0034 train_loss= 1351.53247 time= 1595.11426\n",
            "Val Loss: 1371\n",
            "Epoch: 0035 train_loss= 1352.39346 time= 1570.22319\n",
            "Val Loss: 1369\n",
            "Epoch: 0035 train_loss= 1348.38238 time= 1607.90768\n",
            "Val Loss: 1368\n",
            "Epoch: 0036 train_loss= 1350.07814 time= 1563.25482\n",
            "Val Loss: 1368\n",
            "Epoch: 0036 train_loss= 1346.74993 time= 1595.91331\n",
            "Val Loss: 1368\n",
            "Epoch: 0037 train_loss= 1349.80027 time= 1561.40026\n",
            "Val Loss: 1367\n",
            "Epoch: 0037 train_loss= 1346.47951 time= 1478.75834\n",
            "Val Loss: 1367\n",
            "Epoch: 0038 train_loss= 1349.54369 time= 1459.96496\n",
            "Val Loss: 1367\n",
            "Epoch: 0038 train_loss= 1346.21901 time= 1590.32215\n",
            "Val Loss: 1367\n",
            "Epoch: 0039 train_loss= 1349.27750 time= 1563.86830\n",
            "Val Loss: 1367\n",
            "Epoch: 0039 train_loss= 1345.95478 time= 1613.36816\n",
            "Val Loss: 1367\n",
            "Epoch: 0040 train_loss= 1349.00963 time= 1503.13110\n",
            "Val Loss: 1367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKJMujsKI2XN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0295b5e1-0fd9-45cf-a0f6-02d920071ce9"
      },
      "source": [
        "count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzYmEd5D4XFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#%%\n",
        "testing = samples[-330:]\n",
        "\n",
        "#%%\n",
        "sizes2=sizer(testing)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJaH3IPS7gET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "2f8065c6-b95d-42c2-fbe5-f65ebc9b806a"
      },
      "source": [
        "            \n",
        "posMom=[]\n",
        "\n",
        "            with torch.no_grad():\n",
        "              model.eval()\n",
        "              for el2 in islice(Testloader,1):\n",
        "                gra2=el2.x.cuda()  ##features \n",
        "                adj2=el2.edge_index.cuda() ## edge matrix \n",
        "                lengs2=torch.LongTensor(np.hstack(np.array(fin2[:100]))).cuda()\n",
        "                r12,mu2,sig2= model(gra2,adj2,lengs2,gra2.shape[0]) ## X , A \n",
        "                loss2 = loss_function(r12,gra2,lengs2,mu2,sig2)\n",
        "                cur_loss2 = loss2.item()\n",
        "                posMom.append(r12)\n",
        "                print(\"Val Loss:\", '%04d' % (cur_loss2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 1384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DGszUT69-fL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#%%\n",
        "alles=[]\n",
        "temp=0\n",
        "for siz in sizes2:\n",
        "  temp+=siz\n",
        "  alles.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIIqcisk-0mx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "a868ed6c-0793-458d-b0dd-d87c46166735"
      },
      "source": [
        " %matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import LogNorm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using matplotlib backend: agg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsqfKY1q2TJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real=testing[1]['x']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq8tD13i2Pgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "#xmin, xmax = min(lis4[:,0]), max(lis4[:,0])\n",
        "#ymin, ymax = min(lis4[:,1]), max(lis4[:,1])\n",
        "for k in range(10):\n",
        "  real=testing[k]['x']\n",
        "  xmin,xmax=0,125\n",
        "  ymin,ymax=0,125\n",
        "  binsxy = [int((xmax - xmin) / 50), int((ymax - ymin) / 50)]\n",
        "  weights=np.exp(-real[:,2]/10)\n",
        "  plt.figure(figsize=(7,6))\n",
        "  sc = plt.scatter(real[:,0],real[:,1],c=weights,cmap='viridis',norm=LogNorm(), alpha=0.9)\n",
        "  plt.colorbar(sc)\n",
        "  check=np.arange(0,140,10)\n",
        "  plt.xticks(check)\n",
        "  plt.yticks(check)\n",
        "  plt.grid()\n",
        "  #plt.savefig('./Real2/fig'+str(k)+'.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEcpvp0e-aR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "#xmin, xmax = min(lis4[:,0]), max(lis4[:,0])\n",
        "#ymin, ymax = min(lis4[:,1]), max(lis4[:,1])\n",
        "k1,k2=0,1\n",
        "for j in range(10):\n",
        "  \n",
        "  lis4=r12[alles[k1]:alles[k2]].detach().cpu().clone()\n",
        "  xmin,xmax=0,125\n",
        "  ymin,ymax=0,125\n",
        "  binsxy = [int((xmax - xmin) / 50), int((ymax - ymin) / 50)]\n",
        "  weights=np.exp(-lis4[:,2]/10)\n",
        "  plt.figure(figsize=(7,6))\n",
        "  sc = plt.scatter(lis4[:,0],lis4[:,1],c=weights,cmap='viridis', norm=LogNorm(),alpha=0.9)\n",
        "  plt.colorbar(sc)\n",
        "  check=np.arange(0,140,10)\n",
        "  plt.xticks(check)\n",
        "  plt.yticks(check)\n",
        "  plt.grid()\n",
        "  k1+=1\n",
        "  k2+=1\n",
        "  #plt.savefig('./Rec2/rec'+str(j)+'.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuyt9W72YbGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  lis4=r12[215:691].detach().cpu().clone()\n",
        "  xmin,xmax=0,125\n",
        "  ymin,ymax=0,125\n",
        "  binsxy = [int((xmax - xmin) / 50), int((ymax - ymin) / 50)]\n",
        "  weights=np.exp(-10*lis4[:,2])\n",
        "  plt.figure(figsize=(7,6))\n",
        "  sc = plt.scatter(lis4[:,0]*100,lis4[:,1]*100,c=weights,cmap='viridis', norm=LogNorm(),alpha=0.9)\n",
        "  plt.colorbar(sc)\n",
        "  check=np.arange(0,140,10)\n",
        "  plt.xticks(check)\n",
        "  plt.yticks(check)\n",
        "  plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMRIauxL-6cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "#xmin, xmax = min(lis4[:,0]), max(lis4[:,0])\n",
        "#ymin, ymax = min(lis4[:,1]), max(lis4[:,1])\n",
        "\n",
        "k1,k2=0,1\n",
        "for j in range(9):\n",
        "  lis4=r12[alles[k1]:alles[k2]].detach().cpu().clone()\n",
        "  xmin,xmax=0,125\n",
        "  ymin,ymax=0,125\n",
        "  binsxy = [int((xmax - xmin) / 50), int((ymax - ymin) / 50)]\n",
        "  weights=np.exp(-10*lis4[:,2])\n",
        "  plt.figure(figsize=(7,6))\n",
        "  sc = plt.scatter(lis4[:,0]*100,lis4[:,1]*100,c=weights,cmap='viridis', norm=LogNorm(),alpha=0.9)\n",
        "  plt.colorbar(sc)\n",
        "  check=np.arange(0,140,10)\n",
        "  plt.xticks(check)\n",
        "  plt.yticks(check)\n",
        "  plt.grid()\n",
        "  k1+=1\n",
        "  k2+=1\n",
        "  \n",
        "  #plt.savefig('./Rec/rec'+str(j)+'.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}